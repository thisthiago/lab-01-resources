{"id":"2KR9VSJ8Y","name":"Persistência, Partições e RDDs","paragraphs":[{"text":"%md \r\n# O que são Partições no Spark?\r\n\r\nPartições são pedaços menores dos seus dados que podem ser processados em paralelo por diferentes núcleos de CPU ou nós do cluster.\r\n1. Cada partição é armazenada separadamente\r\n2. As partições podem ser recuperadas individualmente\r\n3. Isso permite processamento paralelo eficiente\r\n\r\n### Pense em um livro grande:\r\n\r\n- O livro inteiro = seu conjunto de dados completo\r\n- Cada capítulo = uma partição\r\n- Várias pessoas podem ler capítulos diferentes ao mesmo tempo (processamento paralelo)\r\n\r\n### Características:\r\n- Cada partição é processada por uma tarefa (task) separada\r\n- O Spark trabalha com 1-4 partições por núcleo de CPU\r\n- O número ideal depende do tamanho dos dados e do cluster\r\n\r\n```\r\nRDD (Dados completos)\r\n│\r\n├─ Partição 1 (Persistida no Nó 1)\r\n├─ Partição 2 (Persistida no Nó 2)\r\n└─ Partição 3 (Persistida no Nó 3)\r\n```","user":"anonymous","dateUpdated":"Apr 14, 2025, 7:39:22 PM","progress":0,"config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>O que são Partições no Spark?</h1>\n<p>Partições são pedaços menores dos seus dados que podem ser processados em paralelo por diferentes núcleos de CPU ou nós do cluster.</p>\n<ol>\n<li>Cada partição é armazenada separadamente</li>\n<li>As partições podem ser recuperadas individualmente</li>\n<li>Isso permite processamento paralelo eficiente</li>\n</ol>\n<h3>Pense em um livro grande:</h3>\n<ul>\n<li>O livro inteiro = seu conjunto de dados completo</li>\n<li>Cada capítulo = uma partição</li>\n<li>Várias pessoas podem ler capítulos diferentes ao mesmo tempo (processamento paralelo)</li>\n</ul>\n<h3>Características:</h3>\n<ul>\n<li>Cada partição é processada por uma tarefa (task) separada</li>\n<li>O Spark trabalha com 1-4 partições por núcleo de CPU</li>\n<li>O número ideal depende do tamanho dos dados e do cluster</li>\n</ul>\n<pre><code>RDD (Dados completos)\n│\n├─ Partição 1 (Persistida no Nó 1)\n├─ Partição 2 (Persistida no Nó 2)\n└─ Partição 3 (Persistida no Nó 3)\n</code></pre>\n\n</div>"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744659359598_1107261390","id":"paragraph_1744659359598_1107261390","dateCreated":"Apr 14, 2025, 7:35:59 PM","dateStarted":"Apr 14, 2025, 7:39:22 PM","dateFinished":"Apr 14, 2025, 7:39:22 PM","status":"FINISHED"},{"text":"%pyspark\n# 1. Criando um RDD básico\ndados = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nrdd = sc.parallelize(dados)","user":"anonymous","dateUpdated":"Apr 14, 2025, 8:15:23 PM","progress":0,"config":{"lineNumbers":true,"tableHide":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744659487673_1893675352","id":"paragraph_1744659487673_1893675352","dateCreated":"Apr 14, 2025, 7:38:07 PM","dateStarted":"Apr 14, 2025, 7:40:01 PM","dateFinished":"Apr 14, 2025, 7:40:14 PM","status":"FINISHED"},{"text":"%pyspark\n# 2. Verificando o número de partições\nnum_particoes = rdd.getNumPartitions()\nprint(f\"Número inicial de partições: {num_particoes}\")","user":"anonymous","dateUpdated":"Apr 14, 2025, 7:40:17 PM","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Número inicial de partições: 8\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744659601615_153640486","id":"paragraph_1744659601615_153640486","dateCreated":"Apr 14, 2025, 7:40:01 PM","dateStarted":"Apr 14, 2025, 7:40:17 PM","dateFinished":"Apr 14, 2025, 7:40:20 PM","status":"FINISHED"},{"text":"%pyspark\n# 3. Criar com número específico\nrdd = sc.parallelize(dados, 4)\nnum_particoes = rdd.getNumPartitions()\nprint(f\"Número inicial de partições: {num_particoes}\")","user":"anonymous","dateUpdated":"Apr 14, 2025, 7:42:38 PM","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Número inicial de partições: 4\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744659617833_237701994","id":"paragraph_1744659617833_237701994","dateCreated":"Apr 14, 2025, 7:40:17 PM","dateStarted":"Apr 14, 2025, 7:42:17 PM","dateFinished":"Apr 14, 2025, 7:42:21 PM","status":"FINISHED"},{"text":"%md\n# O que é Persistência (Cache) no Spark?\n\nPersistência é a capacidade de armazenar um RDD ou DataFrame na memória (ou disco) para reutilização, evitando ter que recalculá-lo toda vez que for usado.\n\n### Imagine que você está cozinhando:\n- Sem persistência: Toda vez que precisar de um ingrediente picado, você pega o vegetal e pica novamente\n\n- Com persistência: Você pica os vegetais uma vez e guarda em potes (memória) para usar várias vezes\n\n### Por que usar?\n1. Performance: Evita recálculos desnecessários\n2. Eficiência: Reduz tempo de processamento para operações iterativas\n\n### Níveis de persistência:\n\n| Como usar | Descrição |\n| -------- | ----------- |\n| rdd.persist(StorageLevel.MEMORY_ONLY)        |  Só na memória (Default)     |\n| rdd.persist(StorageLevel.MEMORY_AND_DISK)        |Memória primeiro, depois disco|\n|rdd.persist(StorageLevel.DISK_ONLY) |Apenas no disco|\n| rdd.cache()| Atalho para MEMORY_ONLY|\n\n\n\n\n","user":"anonymous","dateUpdated":"Apr 14, 2025, 7:49:04 PM","progress":0,"config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>O que é Persistência (Cache) no Spark?</h1>\n<p>Persistência é a capacidade de armazenar um RDD ou DataFrame na memória (ou disco) para reutilização, evitando ter que recalculá-lo toda vez que for usado.</p>\n<h3>Imagine que você está cozinhando:</h3>\n<ul>\n<li>\n<p>Sem persistência: Toda vez que precisar de um ingrediente picado, você pega o vegetal e pica novamente</p>\n</li>\n<li>\n<p>Com persistência: Você pica os vegetais uma vez e guarda em potes (memória) para usar várias vezes</p>\n</li>\n</ul>\n<h3>Por que usar?</h3>\n<ol>\n<li>Performance: Evita recálculos desnecessários</li>\n<li>Eficiência: Reduz tempo de processamento para operações iterativas</li>\n</ol>\n<h3>Níveis de persistência:</h3>\n<table>\n<thead>\n<tr><th>Como usar</th><th>Descrição</th></tr>\n</thead>\n<tbody>\n<tr><td>rdd.persist(StorageLevel.MEMORY_ONLY)</td><td>Só na memória (Default)</td></tr>\n<tr><td>rdd.persist(StorageLevel.MEMORY_AND_DISK)</td><td>Memória primeiro, depois disco</td></tr>\n<tr><td>rdd.persist(StorageLevel.DISK_ONLY)</td><td>Apenas no disco</td></tr>\n<tr><td>rdd.cache()</td><td>Atalho para MEMORY_ONLY</td></tr>\n</tbody>\n</table>\n\n</div>"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744659683974_1573642386","id":"paragraph_1744659683974_1573642386","dateCreated":"Apr 14, 2025, 7:41:23 PM","dateStarted":"Apr 14, 2025, 7:49:04 PM","dateFinished":"Apr 14, 2025, 7:49:04 PM","status":"FINISHED"},{"text":"%pyspark\n# Criando múltiplos RDDs com diferentes níveis de persistência\nrdd1 = sc.parallelize(range(1000)).cache()  # MEMORY_ONLY\nrdd2 = sc.parallelize(range(1000)).persist(StorageLevel.MEMORY_AND_DISK)\nrdd3 = sc.parallelize(range(1000)).persist(StorageLevel.DISK_ONLY)\n\n# Forçando a persistência\nrdd1.count()\nrdd2.count()\nrdd3.count()\n\n# Listando todos os RDDs persistidos\nprint(\"Todos os RDDs persistidos:\")\nfor rdd_id, rdd_info in sc._jsc.getPersistentRDDs().items():\n    rdd_name = rdd_info.name()\n    storage_level = rdd_info.getStorageLevel()\n    print(f\"ID: {rdd_id}, Nome: {rdd_name}, Storage: {storage_level}\")","user":"anonymous","dateUpdated":"Apr 14, 2025, 7:54:54 PM","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Todos os RDDs persistidos:\nID: 55, Nome: None, Storage: StorageLevel(disk, memory, 1 replicas)\nID: 53, Nome: None, Storage: StorageLevel(memory, 1 replicas)\nID: 57, Nome: None, Storage: StorageLevel(disk, 1 replicas)\n"}]},"apps":[],"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":[{"jobUrl":"http://9382a0befda4:4040/jobs/job?id=26"},{"jobUrl":"http://9382a0befda4:4040/jobs/job?id=26"},{"jobUrl":"http://9382a0befda4:4040/jobs/job?id=27"},{"jobUrl":"http://9382a0befda4:4040/jobs/job?id=27"},{"jobUrl":"http://9382a0befda4:4040/jobs/job?id=28"},{"jobUrl":"http://9382a0befda4:4040/jobs/job?id=28"}],"interpreterSettingId":"spark"}},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744660173012_1740958194","id":"paragraph_1744660173012_1740958194","dateCreated":"Apr 14, 2025, 7:49:33 PM","dateStarted":"Apr 14, 2025, 7:54:54 PM","dateFinished":"Apr 14, 2025, 7:54:58 PM","status":"FINISHED"},{"text":"%pyspark\n# Nomeando rdd\nrdd1.setName(\"meu_rdd_importante\")","user":"anonymous","dateUpdated":"Apr 14, 2025, 7:55:58 PM","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"meu_rdd_importante PythonRDD[53] at RDD at PythonRDD.scala:53\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744660271165_2039720659","id":"paragraph_1744660271165_2039720659","dateCreated":"Apr 14, 2025, 7:51:11 PM","dateStarted":"Apr 14, 2025, 7:55:58 PM","dateFinished":"Apr 14, 2025, 7:56:00 PM","status":"FINISHED"},{"text":"%pyspark\n# Listando RDDs persistidos \npersistent_rdds = spark.sparkContext._jsc.getPersistentRDDs().items()\n\nif not persistent_rdds:\n    print(\"Nenhum RDD persistido encontrado\")\nelse:\n    print(\"RDDs Persistidos:\")\n    for rdd_id, rdd_info in persistent_rdds:\n        print(f\"\\nID: {rdd_id}\")\n        print(f\"Nome: {rdd_info.name()}\")\n        print(f\"Nível de Armazenamento: {rdd_info.getStorageLevel()}\")","user":"anonymous","dateUpdated":"Apr 14, 2025, 7:56:25 PM","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Nenhum RDD persistido encontrado\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744660399069_885239147","id":"paragraph_1744660399069_885239147","dateCreated":"Apr 14, 2025, 7:53:19 PM","dateStarted":"Apr 14, 2025, 7:56:25 PM","dateFinished":"Apr 14, 2025, 7:56:28 PM","status":"FINISHED"},{"text":"%pyspark\n# Despersistindo todos os RDDs\nfor rdd_id, rdd_info in sc._jsc.getPersistentRDDs().items():\n    rdd_info.unpersist()\n    print(f\"RDD {rdd_id} despersistido\")","user":"anonymous","dateUpdated":"Apr 14, 2025, 7:56:13 PM","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"JavaObject id=o429\nRDD 55 despersistido\nJavaObject id=o431\nRDD 53 despersistido\nJavaObject id=o433\nRDD 57 despersistido\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1744660471440_1370579510","id":"paragraph_1744660471440_1370579510","dateCreated":"Apr 14, 2025, 7:54:31 PM","dateStarted":"Apr 14, 2025, 7:56:13 PM","dateFinished":"Apr 14, 2025, 7:56:15 PM","status":"FINISHED"}],"info":{},"noteForms":{},"noteParams":{},"angularObjects":{}}